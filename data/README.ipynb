{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOAP: Semantic-Oriented Alignment for Prescription Generation\n",
    "\n",
    "- author: Jiale Cai\n",
    "- date: 2025-03-30\n",
    "- email: mc36401@um.edu.mo\n",
    "\n",
    "## 0. Data Overview\n",
    "\n",
    "We will use the first case from our test dataset for demonstration. Load the test case using following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": 1, \n",
      "    \"question\": \"患者男，3岁7月。饱食后呕吐半年余，加重1日。患儿半年前无明显诱因出现餐后呕吐不消化食物，口气臭秽，脘腹胀满，吐后觉舒，大便秘结，泻下酸臭，未予以重视，1日前呕吐量较以往增多，行腹部DR提示不完全性肠梗阻。舌质红，苔厚腻，脉滑数有力，指纹紫滞。\",\n",
      "    \"answer\": {\n",
      "        \"symptoms\": [\"呕吐\", \"腹胀\", \"便秘\", \"指纹紫滞\", \"红舌\", \"厚舌苔\", \"腻舌苔\", \"脉有力\", \"数脉\", \"滑脉\"],\n",
      "        \"disease\": \"积滞\",\n",
      "        \"syndrome\": \"饮食停滞证\",\n",
      "        \"therapy\": [\"消食化滞\",\"和胃降逆\"],\n",
      "        \"formula\": \"保和丸\",\n",
      "        \"herbs\": [\"炒建曲\", \"焦山楂\", \"姜半夏\", \"炒莱菔子\", \"陈皮\", \"连翘\", \"生姜\", \"炒鸡内金\", \"麸炒枳壳\"]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"test.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "    test = data[0]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diagnostic Interpretation (ID:1)\n",
    "  - TCM Diagnosis: `Pediatric vomiting (小儿呕吐)` | `Food stagnation syndrome (饮食积滞证)`\n",
    "  - Western Diagnosis: `Intestinal obstruction (肠梗阻)`\n",
    "  - Therapeutic Principle: `Digestive regulation and stomach function normalization (消食导滞，和胃降逆)`\n",
    "  - Recommended Formula: `Modified Baohe Pill` - `保和丸加减`.\n",
    "  - Herbal Composition: `\"炒建曲\",\"焦山楂\",\"姜半夏\",\"炒莱菔子\",\"陈皮\",\"连翘\",\"生姜\",\"炒鸡内金\",\"麸炒枳壳\"`\n",
    "\n",
    "Each test case comes from real clinical records, containing:\n",
    "\n",
    "- **\"id\"`**: Unique case identifier\n",
    "- **\"question\"**: Clinical consultation information\n",
    "  - Generally includes patient cheif complaints and medical history (`subjective /S`) and examination findings (`objective/O`)\n",
    "  - Covers TCM diagnostic methods (observation, auscultation, inquiry, palpation) and modern medical tests\n",
    "- **\"answer\"**: Structured diagnosis results\n",
    "  - `Assessment /A`\n",
    "    - **symptoms**: Standardized symptom terms (GB/T 16751.1-2023)\n",
    "    - **disease**: TCM disease diagnosis (GB/T 16751.1-2023)\n",
    "    - **syndrome**: TCM syndrome pattern (GB/T 16751.2-2021)\n",
    "  - `Prescription /P`\n",
    "    - **therapy**: Treatment protocol (GB/T 16751.3-2023)\n",
    "    - **formula**: Herbal formula (GB/T 31773-2015)\n",
    "    - **herbs**: Standardized herb combinations (GB/T 31774-2015)\n",
    "\n",
    "> **Note**: All the terms used here comply with the Chinese terminology standards (the numbers in parentheses refer to GB/T). The recommended herbal combinations are effective prescriptions derived from long-term clinical tracking. In practical applications, clinical physicians make personalized adjustments according to individual conditions. However, the basis for providing the herbal combinations (syndrome, therapy methods, and prescription formula) is uniquely determined. Therefore, when evaluating the prescription generated by the model in the end, its effectiveness should be ultimately determined by clinical practitioners. The “golden answers” (syndrome, therapy methods, and prescription formula) can be assessed through metrics, such as Recall@K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Naive QA System\n",
    "\n",
    "This section presents a simple question and answer system where a user inputs a question and the system generates an answer. We use the `glm-4-flash` model, which is relatively advanced among current models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language model support\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict\n",
    "def chatbot(\n",
    "    APIKEY: str = \"f2ce4abd8dc240762875670e8faaeb73.KnoQbOP7N2kGK2SW\",\n",
    "    BASEURL: str = \"https://open.bigmodel.cn/api/paas/v4/\",\n",
    "    MODEL: str = \"glm-4-flash\",\n",
    "    MESSAGE: List[Dict] = [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Hello!'}]\n",
    "):\n",
    "    client = OpenAI(\n",
    "        api_key=APIKEY,\n",
    "        base_url=BASEURL,\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL, \n",
    "        messages=MESSAGE,\n",
    "        temperature=0.7, # [0,2], the higher the value, the more creative the output\n",
    "        top_p=0.7, # [0,1], the higher the value, the more likely it will generate new words\n",
    "        presence_penalty=-0.5, # [-2, 2] the higher the value, the more likely it will generate new topics\n",
    "        frequency_penalty=1, # [-2, 2] the smaller the value, the more likely it will repeat the same words\n",
    "        n = 1,\n",
    "        max_tokens=2048,\n",
    "        stop=None,\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction of case 1 is: \n",
      " 根据您提供的临床信息，这位3岁7个月的男孩可能患有脾胃湿热型呕吐。以下是对患者症状的推理分析及相应的中草药处方建议：\n",
      "\n",
      "1. **症状分析**：\n",
      "   - 饱食后呕吐：提示脾胃功能失调，饮食不节。\n",
      "   - 口气臭秽：脾胃湿热，浊气上蒸。\n",
      "   - 脘腹胀满：脾胃气机不畅，湿阻中焦。\n",
      "   - 吐后觉舒：脾胃之气暂时得通。\n",
      "   - 大便秘结，泻下酸臭：肠道积热，湿邪内阻。\n",
      "   - 舌质红，苔厚腻：脾胃湿热内蕴。\n",
      "   - 脉滑数有力：内有湿热，脉象滑数为湿邪内阻之象。\n",
      "   - 指纹紫滞：血行不畅，可能为气滞血瘀。\n",
      "\n",
      "2. **诊断**：\n",
      "   - 脾胃湿热型呕吐，不完全性肠梗阻。\n",
      "\n",
      "3. **处方建议**：\n",
      "   - **中草药组成**：\n",
      "     - 黄连：清热燥湿，泻火解毒。\n",
      "     - 黄芩：清热燥湿，泻火解毒，善于清中焦湿热。\n",
      "     - 厚朴：行气化湿，消胀除满。\n",
      "     - 陈皮：理气健脾，燥湿化痰。\n",
      "     - 神曲：消食化积，和中止泻。\n",
      "     - 茯苓：健脾利湿，渗湿止泻。\n",
      "     - 大黄：清热泻火，通便导滞。\n",
      "     - 枳实：破气消积，行气止痛。\n",
      "     - 甘草：调和诸药，缓急止痛。\n",
      "\n",
      "   - **用法**：上述药物按比例配伍，煎煮成汤剂，每日一剂，分两次服用。\n",
      "\n",
      "4. **注意事项**：\n",
      "   - 饮食宜清淡易消化，避免油腻、生冷、辛辣食物。\n",
      "   - 注意休息，避免过度劳累。\n",
      "   - 观察病情变化，如有加重或不适，应及时就医。\n",
      "\n",
      "请注意，以上处方仅供参考，具体用药需根据患者的实际情况和医生的建议进行调整。在用药过程中，应密切观察患者的反应，如有不适，应及时停药并咨询医生。\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "    {'role':'system','content':'请你扮演一位临床中医师，你的任务是根据给出的临床信息，对当前患者的症状做进一步的推理，最终给出相应处方的中草药组成。'},\n",
    "    # System Prompts: \"Please acting as a clinical traditional Chinese medicine practitioner. \n",
    "    # Your task is to further deduce the patient's symptoms based on the provided clinical information and \n",
    "    # ultimately prescribe the herbal composition of the traditional Chinese medicine.\"\n",
    "    {'role':'user','content':f'临床信息如下：{test[\"question\"]}'}\n",
    "    # The clinical information are as follow: $test[\"question\"]\n",
    "]\n",
    "\n",
    "pred = chatbot(MESSAGE=message)\n",
    "print(f\"The prediction of case {test['id']} is: \\n {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\n",
    "    \"id\": 1, \n",
    "    \"question\": \"患者男，3岁7月。饱食后呕吐半年余，加重1日。患儿半年前无明显诱因出现餐后呕吐不消化食物，口气臭秽，脘腹胀满，吐后觉舒，大便秘结，泻下酸臭，未予以重视，1日前呕吐量较以往增多，行腹部DR提示不完全性肠梗阻。舌质红，苔厚腻，脉滑数有力，指纹紫滞。\",\n",
    "    \"answer\": {\n",
    "        \"symptoms\": [\"呕吐\", \"腹胀\", \"便秘\", \"指纹紫滞\", \"红舌\", \"厚舌苔\", \"腻舌苔\", \"脉有力\", \"数脉\", \"滑脉\"],\n",
    "        \"disease\": \"呕吐\",\n",
    "        \"syndrome\": \"饮食停滞证\",\n",
    "        \"therapy\": [\"消食化滞\",\"和胃降逆\"],\n",
    "        \"formula\": \"保和丸\",\n",
    "        \"herbs\": [\"炒建曲\", \"焦山楂\", \"姜半夏\", \"炒莱菔子\", \"陈皮\", \"连翘\", \"生姜\", \"炒鸡内金\", \"麸炒枳壳\"]\n",
    "    },\n",
    "    \"prediction\": {\n",
    "        \"disease\": \"呕吐\",\n",
    "        \"syndrome\": \"脾胃湿热证\",\n",
    "        \"therapy\": [\"消食导滞\"],\n",
    "        \"formula\": \"枳实导滞丸\",\n",
    "        \"herbs\": [\"黄连\",\"黄芩\",\"厚朴\",\"陈皮\",\"神曲\",\"茯苓\",\"大黄\",\"枳实\",\"甘草\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Analysis\n",
    "\n",
    "> - The model-selected prescription covers commonly - used Chinese herbs for eliminating `food stagnation`, promoting qi movement to reduce distension, and clearing heat to relieve constipation. These include `\"黄连\",\"黄芩\",\"厚朴\",\"陈皮\",\"神曲\",\"茯苓\",\"大黄\",\"枳实\",\"甘草\"`. They are effective for food accumulation, gastrointestinal qi stagnation, and heat - induced constipation. The addition and subtraction part also considers targeted medication for different symptoms, showing certain flexibility.\n",
    "> - `Lack of consideration for children's physiological characteristics`: Children have relatively weaker spleen and stomach functions, necessitating more cautious medication. Some drugs may conflict or not coordinate well. For example, `大黄 (Rhubarb)` are effective in clearing heat and relieving constipation, but their dosage and combination need to be extra cautious for a 3-year-7-month-old child to avoid adverse reactions such as excessive purging. The model-predicted efficacy of `枳实导滞丸` (Citrus Aurantium and Rhubarb Pill) is stronger than that of the gold standard `保和丸` (Baohe Pill), which may not be suitable for this pediatric patient. Moreover, the syndrome diagnosed by the model is also incorrect (`脾胃湿热证` is wrong)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conventional Retrieval-Augmented Generation (Embedding-based Retrieval EBR)\n",
    "\n",
    "Now, we provide the knowledge and see how the performance of the large model is enhanced with the support of the retrieval system.\n",
    "- The knowledge we provided are come from the authoritative textbook `Traditional Chinese Internal Medicine`, which includes potential solutions for the aforementioned case `\"vomiting\"`.\n",
    "- First, we need to split the text into `text chunks`. Generally, we split the text using a `sliding window approach`. For example, if the sliding window size is 1,500, then we split the text into chunks of 1,500 characters each.\n",
    "- Then we vectorize the text, and here we use `bge-large-zh-v1.5` for embedding.\n",
    "- Finally, we use the retrieval system to query the information and then generate the output with the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\soap\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Conventional RAG \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from FlagEmbedding import FlagModel\n",
    "\n",
    "# embedding models: https://huggingface.co/BAAI/bge-large-zh-v1.5\n",
    "EMBEDDING_MODEL_PATH = \"F:/soap/models/BAAI/bge-large-zh-v1.5\"\n",
    "\n",
    "# Prompts: \"Generate vectors for the following Traditional Chinese Medicine Knowledge to be used for retrieving: \"\n",
    "QUERY_INSTRUCTION = \"为以下中医知识生成向量，以便用于检索：\" \n",
    "\n",
    "# embedding model support\n",
    "class CustomEmbeddingModel(FlagModel):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\n",
    "            model_name_or_path=EMBEDDING_MODEL_PATH,\n",
    "            query_instruction_for_retrieval=QUERY_INSTRUCTION,\n",
    "            use_fp16=False,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "embedding_model = CustomEmbeddingModel()\n",
    "\n",
    "def get_embedding(text:str):\n",
    "    \"\"\"\n",
    "    Get the embedding vector of the given text.\n",
    "    Parameters:\n",
    "        text (str): the text to be embedded\n",
    "\n",
    "    Returns:\n",
    "        np.array: the embedding vector of the given text\n",
    "    \"\"\"\n",
    "    inputs = [text]\n",
    "    with torch.no_grad():\n",
    "        outputs= embedding_model.encode(inputs)\n",
    "    embedding_vector = outputs[0]\n",
    "    return embedding_vector\n",
    "\n",
    "def cos_similarity(q, p):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two vectors.\n",
    "    q,p: vector numpy.array\n",
    "    \"\"\"\n",
    "    return np.dot(q, p) / ((np.linalg.norm(q) * np.linalg.norm(p)) + 1e-8)\n",
    "\n",
    "def text_chunker(file: str, chunk_size: int = 1500) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split the text into chunks of specified size.\n",
    "    Parameters:\n",
    "        file (str): the file path of the text\n",
    "        chunk_size (int): the size of each chunk\n",
    "\n",
    "    Returns:\n",
    "        List[str]: a list of chunks\n",
    "    \"\"\"\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        print(\"The first 50 characters of the text are: \", text[:50])\n",
    "        print(\"The length of the text is: \", len(text))\n",
    "    chunks = [text[i : i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 50 characters of the text are:  第四节 呕吐 呕吐是由于胃失和降、胃气上逆所致的以饮食、痰涎等胃内之物从胃中上涌，自口而出为临床特征\n",
      "The length of the text is:  7594\n",
      "The most relevant chunk is id:4 with a similarity score of 0.6320789831755625\n",
      "{'id': 4, 'vector': array([ 0.04332899,  0.04660345,  0.03002791, ..., -0.04130913,\n",
      "       -0.02275172, -0.04633958], dtype=float32), 'text': '急，郁郁微烦者，为未解也，与大柴胡汤下之则愈。”  《金匮要略·呕吐哕下利病脉证治》：“呕而胸满者，茱萸汤主之。”“呕而肠鸣，心下痞者，半夏泻心汤主之。”“诸呕吐，谷不得下者，小半夏汤主之。”“食已即吐者，大黄甘草汤主之。”  《诸病源候论·呕哕候》：“呕吐者，皆由脾胃虚弱，受于风邪所为也。”  《三因极一病证方论·呕吐叙论》：“呕吐虽本于胃，然所因亦多端，故有饮食寒热气血之不同，皆使人呕吐。”  《医学正传·呕吐》：“外有伤寒，阳明实热太甚而吐逆者；有内伤饮食，填塞太阴，以致胃气不得宣通而吐者；有胃热而吐者；有胃寒而吐者；有久病气虚，胃气衰甚，闻谷气则呕哕者；有脾湿太甚，不能运化精微，致清痰留饮郁滞上中二焦，时时恶心吐清水者，宜各以类推而治之，不可执一见也。”．  《症因脉治·呕吐论》：“秦子曰：呕以声响名，吐以吐物言。有声无物曰呕，有物无声曰吐，有声有物曰呕吐，皆阳明胃家所主。”  【现代研究】  近年来对于呕吐进行了一些研究，取得了一定的成效。王氏治疗神经性呕吐40例，其中属肝胃不和型26例，胃阴不足型8例，肝胆火盛型6例。病程3个月以内23例，3个月至半年15例，半年以上2例。服用下述基本方：伏龙肝、代赭石、半夏、竹茹、茵陈、枳壳、木香、生麦芽、山药、鸡山金。每剂以伏龙肝60g布包先煎20分钟代水，后下诸药煎煮300mi药液，视呕吐轻重分2-3次温服，每次间隔20分钟，每日2剂，早晚各1剂。连续服用10日为1个疗程，并随证略有加减。结果：临床治愈31例（77．5％），好转7例（17．5％），无效2例（5％）[天津中医1991；（6）：17]。  王氏用大黄甘草汤治疗急重呕吐86例，其中反射性呕吐49例，中枢性呕吐31例，原因不明6例；中医辨证分型：邪犯胃脘9例，食浊停积14例，痰饮内阻7例，肝胃不和12例，脾胃虚弱16例，阴津亏虚20例，未分型8例。方药是：大黄6-30g，甘草6—20g，佩兰6-15g。腑实明显者加芒硝3-20g；邪犯胃脘者加藿香、紫苏、半夏、陈皮；脾虚者加党参、白术、山药；阴津亏虚者加西洋参、麦冬、五味子等。煎法：冷水泡三味药10-20分钟，上火煮沸5-10分钟，滤汁备用。温服少量多次。结果服药后24小时内呕吐止，能进少量饮食，计；6例；48小时呕吐缓解或基本停止，能进少量饮食，病情稳定好转，计23例；无效7例。其中1剂止吐36例，2剂止吐24例，3剂止吐15例，4剂止吐4例[辽宁中医杂志1991；（5）：28]。  张氏等用石菖蒲治疗神经性呕吐21例，结果显效15例，有效5例，无效1例。显示石万蒲治疗神经性呕吐有效。方法是将该药捣碎，以纱布包之，加水500ml左右，文火煮沸15分钟后取汁。该药用量以15-20g为宜（1日量）。取汁后宜少量频饮分次进药，每日10-30次不等，这样可防止病人拒药而吐[中医杂志1996；37（12）：711]。  邵氏用麦门冬汤加味治疗胃阴不足型顽固性呕吐42例，均选择大病、久病后期出现的胃阴不足型顽固性呕吐患者，服用麦门冬汤加味：麦门冬、半夏、人参、炙甘草、粳米、大枣、竹茹、石斛、炙枇杷叶等，煎汁少量频服。服药量最少者3剂，最多者9剂，其中治愈20例（47．6％），显效15例（35．7％），有效4例（9．5％），无效3例（7．1％），总有效率92．8％[河南中医1990；10（1）：21]。  高氏等用自拟补脾止吐汤治疗肿瘤化疗后呕吐41例，并设胃复安组33例作为对照，结果治疗组总有效率为85．4％，对照组总有效率为51，5％，显示补脾止吐汤效果明显优于胃复安（P<0．005），表明中医'}\n"
     ]
    }
   ],
   "source": [
    "vomiting_knowledge = \"vomiting.txt\"\n",
    "vomiting_knowledge_chunks = text_chunker(vomiting_knowledge)\n",
    "vomiting_knowledge_chunks_vector = []\n",
    "for id, chunk in enumerate(vomiting_knowledge_chunks):\n",
    "    vomiting_knowledge_chunks_vector.append({\"id\": id, \"vector\": get_embedding(chunk), \"text\": chunk})\n",
    "\n",
    "score = 0\n",
    "query_vector = get_embedding(test[\"question\"])\n",
    "for vk in vomiting_knowledge_chunks_vector:\n",
    "    sim_score = cos_similarity(query_vector, vk['vector'])\n",
    "    if sim_score > score:\n",
    "        score = sim_score\n",
    "        most_relevant_chunk_id = vk['id'] \n",
    "print(f\"The most relevant chunk is id:{most_relevant_chunk_id} with a similarity score of {score}\")\n",
    "print(vomiting_knowledge_chunks_vector[most_relevant_chunk_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction of case 1 is: \n",
      " 根据所提供的临床信息，患者为3岁7个月大的男孩，主要症状为饱食后呕吐半年余，加重1日，伴有口气臭秽、脘腹胀满、大便秘结、泻下酸臭等。结合舌质红、苔厚腻、脉滑数有力、指纹紫滞等体征，可以推断患者可能存在脾胃湿热、气机不畅、胃热内蕴等问题。\n",
      "\n",
      "结合《金匮要略》中的相关论述，患者症状与“呕而胸满者，茱萸汤主之”以及“呕而肠鸣，心下痞者，半夏泻心汤主之”相符合。因此，可以采用以下中草药组成方剂：\n",
      "\n",
      "**处方：**\n",
      "1. 黄连6g - 清热燥湿，泻火解毒\n",
      "2. 黄芩9g - 清热燥湿，泻火解毒\n",
      "3. 姜半夏9g - 化痰止呕，降逆止呕\n",
      "4. 党参9g - 健脾益气，扶正固本\n",
      "5. 干姜6g - 温中散寒，回阳救逆\n",
      "6. 大枣4枚 - 补中益气，调和诸药\n",
      "7. 炙甘草6g - 补中益气，调和诸药\n",
      "8. 茯苓9g - 利水渗湿，健脾宁心\n",
      "9. 竹茹9g - 清热化痰，降逆止呕\n",
      "10. 枳实9g - 行气化湿，消痞除满\n",
      "\n",
      "**煎服法：**\n",
      "将上述中草药加水1000ml，煎煮30分钟，去渣取汁，分早晚两次温服。\n",
      "\n",
      "**注意事项：**\n",
      "1. 本方剂适用于脾胃湿热、气机不畅、胃热内蕴的患者，如症状不符，请及时调整。\n",
      "2. 建议患者饮食清淡，避免油腻、辛辣、生冷食物。\n",
      "3. 若症状加重或持续不缓解，请及时就医。\n",
      "\n",
      "以上处方仅供参考，具体用药请遵医嘱。\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "    {'role':'system','content':'请你扮演一位临床中医师，你的任务是根据给出的临床信息，对当前患者的症状做进一步的推理，最终给出相应处方的中草药组成。'},\n",
    "    # System Prompts: \"Please acting as a clinical traditional Chinese medicine practitioner. \n",
    "    # Your task is to further deduce the patient's symptoms based on the provided clinical information and \n",
    "    # ultimately prescribe the herbal composition of the traditional Chinese medicine.\"\n",
    "    {'role':'user','content':f'临床信息如下：{test[\"question\"]}\\n补充参考资料：{vomiting_knowledge_chunks[most_relevant_chunk_id]}'}\n",
    "    # Add support text\n",
    "]\n",
    "\n",
    "pred = chatbot(MESSAGE=message)\n",
    "print(f\"The prediction of case {test['id']} is: \\n {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\n",
    "    \"id\": 1, \n",
    "    \"question\": \"患者男，3岁7月。饱食后呕吐半年余，加重1日。患儿半年前无明显诱因出现餐后呕吐不消化食物，口气臭秽，脘腹胀满，吐后觉舒，大便秘结，泻下酸臭，未予以重视，1日前呕吐量较以往增多，行腹部DR提示不完全性肠梗阻。舌质红，苔厚腻，脉滑数有力，指纹紫滞。\",\n",
    "    \"answer\": {\n",
    "        \"symptoms\": [\"呕吐\", \"腹胀\", \"便秘\", \"指纹紫滞\", \"红舌\", \"厚舌苔\", \"腻舌苔\", \"脉有力\", \"数脉\", \"滑脉\"],\n",
    "        \"disease\": \"呕吐\",\n",
    "        \"syndrome\": \"饮食停滞证\",\n",
    "        \"therapy\": [\"消食化滞\",\"和胃降逆\"],\n",
    "        \"formula\": \"保和丸\",\n",
    "        \"herbs\": [\"炒建曲\", \"焦山楂\", \"姜半夏\", \"炒莱菔子\", \"陈皮\", \"连翘\", \"生姜\", \"炒鸡内金\", \"麸炒枳壳\"]\n",
    "    },\n",
    "    \"prediction\": {\n",
    "        \"disease\": \"呕吐\",\n",
    "        \"syndrome\": \"脾胃湿热证\",\n",
    "        \"therapy\": [\"消食导滞\"],\n",
    "        \"formula\": \"枳实导滞丸\",\n",
    "        \"herbs\": [\"黄连\",\"黄芩\",\"厚朴\",\"陈皮\",\"神曲\",\"茯苓\",\"大黄\",\"枳实\",\"甘草\"]\n",
    "    },\n",
    "    \"prediction_rag\": {\n",
    "        \"disease\": \"呕吐\",\n",
    "        \"syndrome\": \"脾胃湿热证\",\n",
    "        \"therapy\": [\"化痰止呕\",\"行气化湿\"],\n",
    "        \"formula\": \"半夏泻心汤\",\n",
    "        \"herbs\": [\"黄连\",\"黄芩\",\"姜半夏\",\"党参\",\"干姜\",\"大枣\",\"炙甘草\",\"茯苓\",\"竹茹\",\"枳实\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Analysis\n",
    "\n",
    "> This time, the model-selected prescription still covers commonly - used Chinese herbs for eliminating food stagnation, promoting qi movement to reduce distension, and clearing heat to relieve constipation. However, due to the inconsistent text chunks, the generation quality is not as good as before. This is a very common problem in RAG (Retrieval-Augmented Generation), which is mainly caused by `the lack of contextual information` in the text chunks or `the inconsistency and fragmentation of the text` chunks themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Our Methods\n",
    "\n",
    "To address the challenges posed by inconsistent text chunks and the lack of contextual information in traditional RAG models, we introduce a prescription generation system based on Large Language Models (LLM), which seamlessly integrates Retrieval-Augmented Generation (RAG) with semantic networks constructed in a Knowledge Graph (KG).\n",
    "\n",
    "Our system (Figure 1) comprises two phases: \n",
    "- First, during the KG construction phase, our system constructs a comprehensive knowledge graph from the latest medical guidelines and medical literature. It integrates a semantic node structured representation of each medical concept and interlinks them based on relational context. It also generates embedding for each node to facilitate later semantic searching.\n",
    "- Second, during the question-answering phase, our method parses clinical queries to identify named entities and intents. It then navigates within the KG to identify related sub-graphs for generating answers.\n",
    "\n",
    "### 3.1 Semantic Network Construction\n",
    "\n",
    "#### 3.1.1 Graph Structure Definition.\n",
    "\n",
    "In defining the knowledge graph structure for medical knowledge representation, we employ a semantic-level architecture that segregates different medical entities based on **`semantic labels`**, as illustrated in Figure 1.\n",
    "\n",
    "- The **Semantic Nodes** $N_i(A,E,R)$ models each medical concept $c_i$ as a node, where attribute $(label_{i}:id_{i})∈A$ is a unique combination of a semantic label and a code, corresponding to a distinct medical concept entity $c_{i}$ that belongs to a specific semantic space $label$. Each edge $e∈E$ and relation $r∈R$ signifies the hierarchical connection and type of relations within context of concepts $c_{i}$.\n",
    "\n",
    "- The **Semantic Network Graph** $G(N,E,R)$ represents the network of connections across different semantic concepts, incorporating both explicit links $E_{exp}$, defined in medical knowledge, and implicit connections $E_{imp}$, derived from semantic similarity between medical concepts. For implicit connections, we leverage cosine similarity between the embedding vectors of text-rich parts of medical description, a method adaptable to specific use cases.\n",
    "\n",
    "For instance, Figure 1 portrays \"Common Cold\" as a semantic nodes. It exhibits a direct linkage to \"Wind-heat syndrome\", indicating an explicit relationship. Additionally, it’s implicitly connected with \"Flu\" due to the semantic similarities.\n",
    "\n",
    "#### 3.1.2 Knowledge Graph Construction. \n",
    "\n",
    "Graph construction is delineated into two phases: **Semantic parsing** and **Relation connection**.\n",
    "\n",
    "1) **Semantic Parsing Phase**: This phase transforms each text-based semantic entity description (e.g definition of one specific disease) $n_i$ into a node representation $N_{i}$. \n",
    "\n",
    "    We employ a hybrid methodology, initially utilizing rule-based extraction for predefined fields, such as \"symptoms:\" identified via keywords. Subsequently, for text not amenable to rule-based parsing, we engage an LLM for parsing. The LLM is directed by a YAML template $T_{template}$, representing in graph the medical concepts routinely utilized by clinical support.\n",
    "\n",
    "$$N_{i} = RuleParse(n_{i,rule}) ∪ LLMParse(n_{i,llm}, T_{template}, prompt)$$\n",
    "\n",
    "1) **Relation Connection Phase**: Here, individual node $N_{i}$ are amalgamated into a comprehensive graph $G$. \n",
    "\n",
    "- Explicit connections $E_{exp}$ are delineated as specified within medical standards, exemplified by designated fields in GB/T (Chinese National Recommended Standard). \n",
    "\n",
    "$$E_{exp} = {(N_{i}, N_{j}) | N_{i} \\text{ explicitly connected to } N_{j} }$$\n",
    "\n",
    "- Implicit connections $E_{imp}$ are inferred from textual-semantic similarities across different semantic concepts, employing embedding techniques and a threshold mechanism to discern the most relevant medical entity for each medical concept.\n",
    "\n",
    "$$E_{imp} = {(N_{i}, N_{j}) | cos(embed(N_{i}), embed(N_{j}) )  > \\Theta }$$\n",
    "\n",
    "#### 3.1.3 Embedding Generation. \n",
    "\n",
    "To support embedding-based retrieval, we generate embeddings for graph node values using pre-trained text-embedding models like BGE[], specifically targeting nodes for text-rich sections such as \"Criteria of diagnosis and differentiation\" and \"Recommendation\", etc. These embeddings are then stored in a vector database (for instance, Neo4j[] and Milvus[]). For most cases the text-length within each node can meet the text-embedding model’s context length constraints, but for certain lengthy texts,we can safely divide the text into smaller chunks for individual embedding without worrying about quality since the text all belong to the same section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第四章 脾胃肠病证 - 第四节 呕吐 - 【辨证论治】:\n",
      "Knowledge  Point: 1: ·外邪犯胃  症状：呕吐食物，吐出有力，突然发生，起病较急，常伴有恶寒发热，胸脘满闷，不思饮食，舌苔白，脉濡缓。  治法：疏邪解表，和胃降逆。  方药：藿香正气散。  方中藿香、紫苏、白芷芳香化浊，疏邪解表；厚朴、大腹皮理气除满；白术、茯苓、甘草健脾化湿；陈皮、半夏和胃降逆，共奏疏邪解表，和胃降逆止呕之功。若风邪偏重，寒热无汗，可加荆芥、防风以疏风散寒；若见胸闷腹胀嗳腐。为兼食滞，可加鸡内金、神曲、莱菔子以消积化滞；若身痛，腰痛，头身困重，苔厚腻者，为兼外湿，可加羌活、独活、苍术以除湿健脾；若暑邪犯胃，身热汗出，可用新加香薷饮以解暑化湿；若秽浊犯胃，呕吐甚剧，可吞服玉枢丹以辟秽止呕；若风热犯胃、头痛身热可用银翘散去桔梗之升提，加陈皮、竹茹疏风清热，和胃降逆。\n",
      "Nodes Representation with Json format: [\n",
      "    {\n",
      "        \"id\": 0,\n",
      "        \"attributes\": {\n",
      "            \"name\": \"外邪犯胃证\",\n",
      "            \"label\": \"Syndrome\",\n",
      "            \"symptoms\": \"呕吐食物，吐出有力，突然发生，起病较急，常伴有恶寒发热，胸脘满闷，不思饮食，舌苔白，脉濡缓。\"\n",
      "        },\n",
      "        \"relations\": [\n",
      "            {\n",
      "                \"Syndrome\": \"外邪犯胃证\",\n",
      "                \"Therapy\": \"疏邪解表\",\n",
      "                \"Relation\": \"HAS_THERAPY\"\n",
      "            },\n",
      "            {\n",
      "                \"Syndrome\": \"外邪犯胃证\",\n",
      "                \"Therapy\": \"和胃降逆\",\n",
      "                \"Relation\": \"HAS_THERAPY\"\n",
      "            },\n",
      "            {\n",
      "                \"Syndrome\": \"外邪犯胃证\",\n",
      "                \"Formula\": \"藿香正气散\",\n",
      "                \"Relation\": \"HAS_FORMULA\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Rule-based Parse Example (Ni = RuleParse(ni,rule)\n",
    "\n",
    "import re\n",
    "def rule_parse(text:str)->dict:\n",
    "    \"\"\"\n",
    "    Content structure parse by rule-based method: chapter -> section -> paragraph -> knowledge point\n",
    "    \"\"\"\n",
    "    # chapter parse\n",
    "    chapter_pattern = re.compile(r'(第[一二三四五六七八九十]+章\\s*[^\\u4e00-\\u9fa5]*[\\u4e00-\\u9fa5]+)(.*?)(?=第[一二三四五六七八九十]+章|$)') # chapter keywords\n",
    "    chapters = chapter_pattern.findall(text)\n",
    "    \n",
    "    result = {}\n",
    "    for chapter in chapters:\n",
    "        chapter_title = chapter[0].strip()\n",
    "        chapter_content = chapter[1]\n",
    "\n",
    "        # section parse\n",
    "        section_pattern = re.compile(r'(第[一二三四五六七八九十]+节\\s*[^\\u4e00-\\u9fa5]*[\\u4e00-\\u9fa5]+)(.*?)(?=第[一二三四五六七八九十]+节|$)')  # section keywords\n",
    "        sections = section_pattern.findall(chapter_content)\n",
    "\n",
    "        chapter_data = {}\n",
    "        for section in sections:\n",
    "            section_title = section[0].strip()\n",
    "            section_content = section[1]\n",
    "\n",
    "            # paragraph parse\n",
    "            paragraph_pattern = re.compile(r'(【[^】]+】)(.*?)(?=【|$)')  # paragraph keywords\n",
    "            paragraphs = paragraph_pattern.findall(section_content)\n",
    "            \n",
    "            section_data = {}\n",
    "            for paragraph in paragraphs:\n",
    "                paragraph_title = paragraph[0].strip()\n",
    "                paragraph_content = paragraph[1].strip()\n",
    "\n",
    "                # knowledge point parse\n",
    "                knowledge_pattern = re.compile(r'(?<=\\s)(·[\\u4e00-\\u9fa5]{4}.*?)(?=·[\\u4e00-\\u9fa5]{4}|$)') # knowledge point keywords\n",
    "                knowledges = knowledge_pattern.findall(paragraph_content)\n",
    "\n",
    "                if knowledges:\n",
    "                    knowledge_data = []\n",
    "                    for knowledge in knowledges:\n",
    "                        knowledge_data.append(knowledge.strip())\n",
    "                    section_data[paragraph_title] = knowledge_data\n",
    "                else:\n",
    "                    section_data[paragraph_title] = paragraph_content\n",
    "            \n",
    "            chapter_data[section_title] = section_data\n",
    "        \n",
    "        result[chapter_title] = chapter_data\n",
    "\n",
    "    return result\n",
    "\n",
    "import json\n",
    "def knowledge_parse(text:str):\n",
    "    \"\"\"\n",
    "    Knowledge parse by rule-based method: \n",
    "    \"\"\"\n",
    "    # Extract components using regular expressions\n",
    "    name_match = re.search(r\"·(.+?)\\s+症状\", text)\n",
    "    symptoms_match = re.search(r\"症状：(.+?)\\s+治法\", text)\n",
    "    therapy_match = re.search(r\"治法：(.+?)\\s+方药\", text)\n",
    "    formula_match = re.search(r\"方药：(.+?)。\", text)\n",
    "\n",
    "    if name_match and symptoms_match and therapy_match and formula_match:\n",
    "        name = name_match.group(1) + \"证\"\n",
    "        symptoms = symptoms_match.group(1).strip()\n",
    "        therapies = [t.strip() for t in therapy_match.group(1).strip(\"。\").split(\"，\")]\n",
    "        formula = formula_match.group(1).strip()\n",
    "        \n",
    "        # Build the JSON structure\n",
    "        result = [\n",
    "            {\n",
    "                \"id\": 0,\n",
    "                \"attributes\": {\n",
    "                    \"name\": name,\n",
    "                    \"label\": \"Syndrome\",\n",
    "                    \"symptoms\": symptoms,\n",
    "                },\n",
    "                \"relations\": []\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Add therapies to relations\n",
    "        for therapy in therapies:\n",
    "            result[0][\"relations\"].append({\n",
    "                \"Syndrome\": name,\n",
    "                \"Therapy\": therapy,\n",
    "                \"Relation\": \"HAS_THERAPY\"\n",
    "            })\n",
    "        \n",
    "        # Add formula to relations\n",
    "        result[0][\"relations\"].append({\n",
    "            \"Syndrome\": name,\n",
    "            \"Formula\": formula,\n",
    "            \"Relation\": \"HAS_FORMULA\"\n",
    "        })\n",
    "        \n",
    "        # Convert to JSON with proper Unicode handling and indentation\n",
    "        formatted_json = json.dumps(result, ensure_ascii=False, indent=4)\n",
    "        return(formatted_json)\n",
    "\n",
    "# Example\n",
    "with open(\"corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read().replace(\"\\n\", \" \")\n",
    "\n",
    "parsed_data = rule_parse(text)\n",
    "\n",
    "# Example: Access the content of \"Differential Diagnosis and Treatment\" in Section 2 of Chapter 4\n",
    "# Note: The key names here need to be adjusted according to the actual text\n",
    "example_chapter = \"第四章 脾胃肠病证\"\n",
    "example_section = \"第四节 呕吐\"\n",
    "example_paragraph = \"【辨证论治】\"\n",
    "\n",
    "if example_chapter in parsed_data:\n",
    "    if example_section in parsed_data[example_chapter]:\n",
    "        if example_paragraph in parsed_data[example_chapter][example_section]:\n",
    "            print(f\"{example_chapter} - {example_section} - {example_paragraph}:\")\n",
    "            content = parsed_data[example_chapter][example_section][example_paragraph]\n",
    "            if isinstance(content, list):\n",
    "                for i, knowledge in enumerate(content, 1):\n",
    "                    print(f\"Knowledge  Point: {i}: {knowledge}\")\n",
    "                    print(f\"Nodes Representation with Json format: {knowledge_parse(knowledge)}\")\n",
    "                    break\n",
    "            else:\n",
    "                print(content)\n",
    "        else:\n",
    "            print(f\"段落 '{example_paragraph}' 未找到\")\n",
    "    else:\n",
    "        print(f\"节 '{example_section}' 未找到\")\n",
    "else:\n",
    "    print(f\"章 '{example_chapter}' 未找到\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-based Parse Result: \n",
      " ```json\n",
      "[\n",
      "  {\n",
      "    \"id\": 0,\n",
      "    \"attributes\": {\n",
      "      \"name\": \"藿香正气散\",\n",
      "      \"label\": \"Formula\",\n",
      "      \"composition\": [\"藿香\", \"紫苏\", \"白芷\", \"厚朴\", \"大腹皮\", \"白术\", \"茯苓\", \"甘草\", \"陈皮\", \"半夏\", \"荆芥\", \"防风\", \"鸡内金\", \"神曲\", \"莱菔子\", \"羌活\", \"独活\", \"苍术\", \"香薷\", \"玉枢丹\", \"银翘散\", \"陈皮\", \"竹茹\"],\n",
      "      \"function\": [\"芳香化浊\", \"疏邪解表\", \"理气除满\", \"健脾化湿\", \"和胃降逆\", \"疏风散寒\", \"消积化滞\", \"除湿健脾\", \"解暑化湿\", \"辟秽止呕\", \"疏风清热\", \"和胃降逆\"]\n",
      "    },\n",
      "    \"relations\": [\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"藿香\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"紫苏\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"白芷\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"厚朴\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"大腹皮\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"白术\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"茯苓\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"甘草\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"陈皮\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"半夏\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"荆芥\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"防风\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"鸡内金\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"神曲\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"莱菔子\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"羌活\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"独活\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"苍术\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"香薷\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"玉枢丹\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"银翘散\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"陈皮\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Herb\": \"竹茹\", \"Relation\": \"HAS_HERB\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Therapy\": \"芳香化浊\", \"Relation\": \"HAS_THERAPY\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Therapy\": \"疏邪解表\", \"Relation\": \"HAS_THERAPY\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Therapy\": \"理气除满\", \"Relation\": \"HAS_THERAPY\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Therapy\": \"健脾化湿\", \"Relation\": \"HAS_THERAPY\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Therapy\": \"和胃降逆\", \"Relation\": \"HAS_THERAPY\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Therapy\": \"疏风散寒\", \"Relation\": \"HAS_THERAPY\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Therapy\": \"消积化滞\", \"Relation\": \"HAS_THERAPY\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Therapy\": \"除湿健脾\", \"Relation\": \"HAS_THERAPY\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Therapy\": \"解暑化湿\", \"Relation\": \"HAS_THERAPY\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Therapy\": \"辟秽止呕\", \"Relation\": \"HAS_THERAPY\"},\n",
      "      {\"Formula\": \"藿香正气散\", \"Therapy\": \"疏风清热\", \"Relation\": \"HAS_THERAPY\"}\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# LLM-based Parse Example LLMParse(n{i,llm}, T{template}, prompt)\n",
    "\n",
    "# load the customized template\n",
    "import yaml\n",
    "with open(\"template.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    template = yaml.safe_load(f)\n",
    "\n",
    "# build up the prompt based on the template\n",
    "def build_prompt(template: dict) -> str:\n",
    "    prompt = \"请执行医学实体识别，要求：\\n\"\n",
    "    \n",
    "    # named entity recognition\n",
    "    if template[\"entities\"]:\n",
    "        prompt += \"1. 识别以下实体类型：\\n\"\n",
    "        for entity in template[\"entities\"]:\n",
    "            prompt += f\"   - {entity['label']}（{entity['description']}），示例：{entity['example']}。{entity['instruction']}\\n\"\n",
    "    \n",
    "    # relation detection\n",
    "    if template.get(\"relations\"):\n",
    "        prompt += \"\\n2. 提取以下语义关系：\\n\"\n",
    "        for rel in template[\"relations\"]:\n",
    "            prompt += f\"   - {rel['from']} → {rel['to']} 的 {rel['type']} 关系：{rel['description']}\\n\"\n",
    "    \n",
    "    # output format\n",
    "    prompt += \"\\n3. 输出要求：\\n\"\n",
    "    prompt += \"   - 使用严格JSON格式输出\\n\"\n",
    "    prompt += \"   - 包含composition（处方组成药材）、function（处方功效）字段\\n\"\n",
    "    prompt += \"   - 关系字段使用Relation指定关系类型\\n\"\n",
    "    prompt += \"   - 确保完整提取所有实体和关系\\n\\n\"\n",
    "    prompt += \"输出示例：\\n\"\n",
    "    prompt += template[\"output_format\"][\"example\"]\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "prompt = build_prompt(template)\n",
    "\n",
    "\"\"\" prompt translation:\n",
    "prompt:\n",
    "\n",
    "Please perform medical entity recognition with the following requirements:\n",
    "1.Recognize the following entity types:\n",
    "    - Formula (Prescription name), example: Mahuang Tang. Identify the prescription names in the input text.\n",
    "    - Herb (Chinese herbal ingredients), example: Huoxiang, Zisu. Identify the herbal ingredients in the prescription.\n",
    "    - Therapy (Therapeutic effect), example: Aromatic turbidity-removing, Evacuating exterior pathogens. Identify the therapeutic effects of the prescription.\n",
    "\n",
    "2. Extract the following semantic relationships:\n",
    "    - Formula → Herb HAS_HERB relationship: The inclusion relationship between the prescription and its herbal ingredients.\n",
    "    - Formula → Therapy HAS_THERAPY relationship: The association between the prescription and its therapeutic effects.\n",
    "\n",
    "3.Output requirements:\n",
    "    - Use strict JSON format for output.\n",
    "    - Include fields for composition (herbal ingredients of the prescription) and function (therapeutic effects of the prescription).\n",
    "    - Use the Relation field to specify the relationship type.\n",
    "    - Ensure that all entities and relationships are fully extracted.\n",
    "\n",
    "Output example:\n",
    "[\n",
    "  {\n",
    "    \"id\": 0,\n",
    "    \"attributes\": {\n",
    "      \"name\": \"藿香正气散\",\n",
    "      \"label\": \"Formula\",\n",
    "      \"composition\": [\"藿香\",\"紫苏\"],\n",
    "      \"function\": [\"芳香化浊\",\"疏邪解表\"]\n",
    "    },\n",
    "    \"relations\": [\n",
    "      {\"Formula\": \"藿香正气散\", \"Herb\": \"藿香\", \"Relation\": \"HAS_HERB\"}\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "# example\n",
    "text = \"\"\"藿香正气散。  方中藿香、紫苏、白芷芳香化浊，疏邪解表；厚朴、大腹皮理气除满；白术、茯苓、甘草健脾化湿；陈皮、半夏和胃降逆，共奏疏邪解表，和胃降逆止呕之功。若风邪偏重，寒热无汗，可加荆芥、防风以疏风散寒；若见胸闷腹胀嗳腐。为兼食滞，可加鸡内金、神曲、莱菔子以消积化滞；若身痛，腰痛，头身困重，苔厚腻者，为兼外湿，可加羌活、独活、苍术以除湿健脾；若暑邪犯胃，身热汗出，可用新加香薷饮以解暑化湿；若秽浊犯胃，呕吐甚剧，可吞服玉枢丹以辟秽止呕；若风热犯胃、头痛身热可用银翘散去桔梗之升提，加陈皮、竹茹疏风清热，和胃降逆。\"\"\"\n",
    "\n",
    "message = [\n",
    "    {'role':'system','content': prompt},\n",
    "    {'role':'user','content':f'Input text：{text}'}\n",
    "]\n",
    "\n",
    "example = chatbot(MESSAGE=message)\n",
    "print(f\"LLM-based Parse Result: \\n {example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `Note`:\n",
    "> The example above illustrates how we use a hybrid approach to process text. We first apply rule-based methods to handle predefined fields (such as the structure of a document's table of contents). If we encounter text that cannot be processed by rules (e.g., text descriptions with irregular lengths), we then use a Large Language Model (LLM) for parsing.\n",
    "> \n",
    "> Features of the Solution:\n",
    "> \n",
    "> - Modular Design: Separation of template configuration and code logic through YAML files, making management and modification easier.\n",
    "> - Precise Control: Clear distinction between different entity types and output rules to prevent LLM from \"free-form\" generation, ensuring the accuracy of results.\n",
    "> - Flexible Expansion: When adding new entity types, simply modify the YAML file without changing the code, making the process straightforward.\n",
    "> - Error Tolerance: Constraints on output rules to avoid empty values or placeholders in the results, thereby improving data quality.\n",
    "> - Format Enhancement: Explicit declaration of output format requirements to make result parsing more reliable.\n",
    "> \n",
    "> Practical Usage Suggestions:\n",
    "> In practical applications, adjustments should be made according to the specific needs of the domain, such as:\n",
    "> - Adding more entity types to the YAML file;\n",
    "> - Enhancing the example vocabulary to provide more comprehensive learning content for the model;\n",
    "> - Adjusting output rules to meet different business requirements;\n",
    "> - Adding special processing logic, such as synonym mapping, to improve processing effectiveness.\n",
    "\n",
    "We store all the standardized processed data in the `data/node` folder, saved in `json` format. In the next step, we will use these semantic nodes and semantic relationships to build a semantic graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neo4j\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import ServiceUnavailable, AuthError\n",
    "\n",
    "def neo4j_connector(\n",
    "    uri=\"bolt://localhost:7687\", \n",
    "    username=\"neo4j\", \n",
    "    password=\"neo4j@soap\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Connect to Neo4j instance.\n",
    "    \"\"\"\n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    return driver\n",
    "\n",
    "driver = neo4j_connector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entity(\n",
    "    tx, \n",
    "    entity_name:str, \n",
    "    entity_label:str, \n",
    "    entity_attributes:dict, \n",
    "    entity_relations:list, \n",
    "):\n",
    "    \"\"\"\n",
    "    Initialize all entity nodes information into the graph database.\n",
    "    \"\"\"\n",
    "    # Add entity attributes\n",
    "    tx.run(\n",
    "        f\"\"\"\n",
    "        MERGE (e:`Entity`:`{entity_label}` {{name:$name}})\n",
    "        SET e += $attributes\n",
    "        \"\"\",\n",
    "        name=entity_name,\n",
    "        attributes=entity_attributes,\n",
    "    )\n",
    "\n",
    "    # Create entity relations\n",
    "    if entity_relations:\n",
    "        for relation in entity_relations:\n",
    "            relation = list(relation.items())\n",
    "            source_label = relation[0][0]\n",
    "            source_name = relation[0][1]\n",
    "            target_label = relation[1][0]\n",
    "            target_name = relation[1][1]\n",
    "            relation_label = relation[2][0]\n",
    "            relation_name = relation[2][1]\n",
    "\n",
    "            cypher = f\"\"\"\n",
    "            MERGE (s:`Entity`:`{source_label}` {{name: $source_name}})\n",
    "            MERGE (t:`Entity`:`{target_label}` {{name: $target_name}})\n",
    "            MERGE (s)-[:`{relation_name}`]->(t)\n",
    "            \"\"\"\n",
    "            tx.run(cypher, source_name=source_name, target_name=target_name)\n",
    "\n",
    "def node2vec(\n",
    "    tx, \n",
    "    entity_name:str, \n",
    "    entity_label:str, \n",
    "    entity_vector_text: str = \"\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the embedding vector of the given text and create node embedding vector.\n",
    "    \"\"\"\n",
    "    # Get the embedding vector of the given text.\n",
    "    entity_vector = get_embedding(entity_vector_text)\n",
    "    # Create node embedding vector\n",
    "    tx.run(\n",
    "        f\"\"\"\n",
    "        MERGE (e:`Entity`:`{entity_label}` {{name:$name}})\n",
    "        WITH e\n",
    "        CALL db.create.setNodeVectorProperty(e, 'embedding', $embedding)\n",
    "        \"\"\",\n",
    "        name=entity_name,\n",
    "        embedding=entity_vector\n",
    "    )\n",
    "\n",
    "def _index_exists(tx, index_name: str) -> bool:\n",
    "    result = tx.run(\"SHOW INDEXES\")\n",
    "    for record in result:\n",
    "        if record[\"name\"] == index_name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def _create_vector_index(tx, label: str, dim: int):\n",
    "    \"\"\"\n",
    "    Create vector index for the given label.\n",
    "    This is used to sperate different entity into different search spaces.\n",
    "    \"\"\"\n",
    "    if label == \"entityEmbeddings\":\n",
    "        label = \"Entity\"\n",
    "        LABEL = \"entityEmbeddings\"\n",
    "    else:\n",
    "        LABEL = label.upper()\n",
    "    if not _index_exists(tx, LABEL):\n",
    "        tx.run(f\"\"\"\n",
    "        CREATE VECTOR INDEX {LABEL}\n",
    "        FOR (n: `{label}`) ON (n.embedding)\n",
    "        OPTIONS {{\n",
    "            indexConfig: {{\n",
    "                `vector.dimensions`: {dim},\n",
    "                `vector.similarity_function`: 'cosine'\n",
    "            }}\n",
    "        }};\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "def jsonl_loader(file_path):\n",
    "    with jsonlines.open(file_path, 'r') as reader:\n",
    "        data = list(reader)\n",
    "    return data\n",
    "\n",
    "symptoms = jsonl_loader(\"./data/node/symptoms.json\")\n",
    "diseases = jsonl_loader(\"./data/node/diseases.json\")\n",
    "syndromes = jsonl_loader(\"./data/node/syndromes.json\")\n",
    "therapies = jsonl_loader(\"./data/node/therapies.json\")\n",
    "formulae = jsonl_loader(\"./data/node/formulae.json\")\n",
    "herbs = jsonl_loader(\"./data/node/herbs.json\")\n",
    "\n",
    "with driver.session() as session:\n",
    "    LABELS = [\"Symptom\", \"Disease\", \"Syndrome\", \"Therapy\", \"Formula\", \"Herb\", \"entityEmbeddings\"]\n",
    "    for label in LABELS:\n",
    "        session.execute_write(_create_vector_index, label, 1024)\n",
    "\n",
    "    for symptom in symptoms:\n",
    "        session.execute_write(\n",
    "            add_entity, \n",
    "            symptom[\"attributes\"][\"name\"], \n",
    "            symptom[\"attributes\"][\"label\"],\n",
    "            symptom[\"attributes\"], \n",
    "            symptom[\"relations\"]\n",
    "        )\n",
    "\n",
    "    for disease in diseases:\n",
    "        session.execute_write(\n",
    "            add_entity, \n",
    "            disease[\"attributes\"][\"name\"], \n",
    "            disease[\"attributes\"][\"label\"], \n",
    "            disease[\"attributes\"], \n",
    "            disease[\"relations\"]\n",
    "        )\n",
    "\n",
    "    for syndrome in syndromes:\n",
    "        session.execute_write(\n",
    "            add_entity, \n",
    "            syndrome[\"attributes\"][\"name\"], \n",
    "            syndrome[\"attributes\"][\"label\"], \n",
    "            syndrome[\"attributes\"], \n",
    "            syndrome[\"relations\"]\n",
    "        )\n",
    "\n",
    "    # Generate embeddings for graph node values using pre-trained text-embedding models such as BERT,\n",
    "    # specifically targeting nodes for text-rich sections\n",
    "    for syndrome in syndromes:\n",
    "        session.execute_write(\n",
    "            node2vec, \n",
    "            syndrome[\"attributes\"][\"name\"], \n",
    "            syndrome[\"attributes\"][\"label\"], \n",
    "            syndrome[\"attributes\"][\"symptoms\"] # text-rich section, the clinical performance of syndrome\n",
    "        )\n",
    "\n",
    "    for therapy in therapies:\n",
    "        session.execute_write(\n",
    "            add_entity, \n",
    "            therapy[\"attributes\"][\"name\"], \n",
    "            therapy[\"attributes\"][\"label\"], \n",
    "            therapy[\"attributes\"], \n",
    "            therapy[\"relations\"]\n",
    "        )\n",
    "\n",
    "    for formula in formulae:\n",
    "        session.execute_write(\n",
    "            add_entity, \n",
    "            formula[\"attributes\"][\"name\"], \n",
    "            formula[\"attributes\"][\"label\"], \n",
    "            formula[\"attributes\"], \n",
    "            formula[\"relations\"]\n",
    "        )\n",
    "\n",
    "    for herb in herbs:\n",
    "        session.execute_write(\n",
    "            add_entity, \n",
    "            herb[\"attributes\"][\"name\"], \n",
    "            herb[\"attributes\"][\"label\"],\n",
    "            herb[\"attributes\"],\n",
    "            herb[\"relations\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Semantic-Oriented Alignment\n",
    "\n",
    "#### 3.2.1 Query Named Entity Identification and Intent Detection. \n",
    "\n",
    "In this step, we extract the named entities C of type Map(N → V) and the query intent set I from each clinical query q. The method involves parsing each query q into a key-value pair, where each key n, mentioned within the query, corresponds to an semantic element in the semantic template $T_{template}$, and the value v represents the information extracted from the query. Concurrently, the query intents I include the medical task mentioned in the graph  $T_{template}$ that the query aims to address. We leverage LLM with a suitable prompt in this parsing process. \n",
    "\n",
    "$$C,I = LLM(q, template, prompt)$$\n",
    "\n",
    "For instance, given the query q = \"What is the potential syndrome of patients with nasal congestion and rhinorrhea for 4 days, fever, chills, and headache for 2 days, a thin yellow tongue coating, and a floating and rapid pulse?\", the extracted entity is C = Map(\n",
    "    \"symptom\" → \"nasal congestion and rhinorrhea for 4 days, fever, chills, and headache for 2 days\",\n",
    "    \"pulseSymptom\" → \"floating and rapid pulse\",\n",
    "    \"tongueSymptom\" → \"thin yellow tongue coating\",\n",
    "), and the intent set is I=Set(\"syndrome differentiation\"). This method demonstrates notable flexibility in accommodating varied query formulations by leveraging the LLM’s extensive understanding and interpretive capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Prompt:请执行医学实体识别，要求：\n",
      "- 【Symptoms】提取所有临床症状描述，包含持续时间、加重情况等细节\n",
      "  示例：'间断性头晕1月。患者自述1月前因劳累出现间断头晕，无头痛，无视物旋转，无双下肢无力，休息后症状有所缓解，但未完全消失，尤以劳累后症状明显，目下症见：患者神清，精神尚可，间断性头晕，食纳欠佳，夜寐尚可，二便调。舌红，苔白腻，脉滑。'\n",
      "- 【Diseases】从候选疾病列表中选择匹配的疾病名称\n",
      "  候选疾病列表：呕吐, 眩晕, 感冒, 肺炎\n",
      "  示例：'眩晕'\n",
      "\n",
      "请严格按以下JSON格式输出：\n",
      "{\n",
      "  \"Symptoms\": \"\",\n",
      "  \"Diseases\": \"\",  # 必须从4个候选疾病中选择\n",
      "}\n",
      "-----------------------\n",
      " \n",
      "Query NER Result: \n",
      " {\n",
      "  \"Symptoms\": \"饱食后呕吐半年余，加重1日，餐后呕吐不消化食物，口气臭秽，脘腹胀满，吐后觉舒，大便秘结，泻下酸臭，不完全性肠梗阻，舌质红，苔厚腻，脉滑数有力，指纹紫滞。\",\n",
      "  \"Diseases\": \"呕吐\"  # 根据症状描述，呕吐是最匹配的候选疾病\n",
      "}\n",
      "-----------------------\n",
      "Prompt:## 意图识别任务说明\n",
      "请分析以下医疗查询的意图，需满足：\n",
      "- 必须从预定义标签集选择：['辩证', '诊断', '治疗建议', '预后评估']\n",
      "- 返回所有相关意图（0到多个）\n",
      "\n",
      "## 候选意图定义\n",
      "辩证：根据四诊信息进行中医证候分析\n",
      "诊断：确定疾病诊断结果\n",
      "治疗建议：获取治疗方案建议\n",
      "预后评估：预测疾病发展及康复情况\n",
      "\n",
      "## 输出要求\n",
      "- 格式：JSON字符串数组\n",
      "- 示例：[\"辩证\", \"治疗建议\"]\n",
      "- 注意：不要添加注释或说明文本\n",
      "-----------------------\n",
      " \n",
      "User Intent Detection Result: \n",
      " Output: [\"辩证\"]\n"
     ]
    }
   ],
   "source": [
    "# template\n",
    "import yaml\n",
    "with open(\"query_ner_template.yaml\", encoding=\"utf-8\") as file:\n",
    "    template = yaml.safe_load(file)\n",
    "\n",
    "##\n",
    "# please check the query_ner_template.yaml\n",
    "##\n",
    "\n",
    "# prompt for named entity extraction\n",
    "def named_entity_extractor(template:dict) -> str:\n",
    "    prompt = \"请执行医学实体识别，要求：\\n\"\n",
    "    for entity in template['entities']:\n",
    "\n",
    "        if entity['label'] == 'Diseases':\n",
    "            candidates = entity.get('candidates', [])\n",
    "            prompt += f\"- 【{entity['label']}】{entity['instruction']}\\n\"\n",
    "            prompt += f\"  候选疾病列表：{', '.join(candidates)}\\n\"  # the candidates are separated by commas\n",
    "            prompt += f\"  示例：'{entity['example']}'\\n\"\n",
    "        else:\n",
    "            prompt += f\"- 【{entity['label']}】{entity['instruction']}\\n\"\n",
    "            prompt += f\"  示例：'{entity['example']}'\\n\"\n",
    "    \n",
    "    # Dynamic Format Generation Constraints\n",
    "    format_desc = \"{\\n\"\n",
    "    for e in template['entities']:\n",
    "        if e['label'] == 'Diseases':\n",
    "            format_desc += f'  \"{e[\"label\"]}\": \"\",  # 必须从{len(e[\"candidates\"])}个候选疾病中选择\\n'\n",
    "        else:\n",
    "            format_desc += f'  \"{e[\"label\"]}\": \"\",\\n'\n",
    "    format_desc += \"}\"\n",
    "    \n",
    "    prompt += f\"\\n请严格按以下JSON格式输出：\\n{format_desc}\"\n",
    "    return prompt\n",
    "\n",
    "# prompt for intent detection\n",
    "def intent_detector(template:dict) -> str:\n",
    "    prompt = \"## 意图识别任务说明\\n\"\n",
    "    prompt += \"请分析以下医疗查询的意图，需满足：\\n\"\n",
    "    prompt += f\"- 必须从预定义标签集选择：{template['intents']['candidates']}\\n\"\n",
    "    prompt += \"- 返回所有相关意图（0到多个）\\n\\n\"\n",
    "    \n",
    "    prompt += \"## 候选意图定义\\n\"\n",
    "    for item in template['intents']['items']:\n",
    "        prompt += f\"{item['task']}：{item['description']}\\n\"\n",
    "    \n",
    "    prompt += \"\\n## 输出要求\\n\"\n",
    "    prompt += \"- 格式：JSON字符串数组\\n\"\n",
    "    prompt += \"- 示例：[\\\"辩证\\\", \\\"治疗建议\\\"]\\n\"\n",
    "    prompt += \"- 注意：不要添加注释或说明文本\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# example test case id 1\n",
    "# test[\"question\"] + \"What is the syndrome of this patient?\"\n",
    "\n",
    "query = \"患者男，3岁7月。饱食后呕吐半年余，加重1日。患儿半年前无明显诱因出现餐后呕吐不消化食物，口气臭秽，脘腹胀满，吐后觉舒，大便秘结，泻下酸臭，未予以重视，1日前呕吐量较以往增多，行腹部DR提示不完全性肠梗阻。舌质红，苔厚腻，脉滑数有力，指纹紫滞。请问该患者的证候是什么？\"\n",
    "print(\"-----------------------\")\n",
    "ner_prompt = named_entity_extractor(template)\n",
    "print(f\"Prompt:{ner_prompt}\")\n",
    "print(\"-----------------------\")\n",
    "print(\" \")\n",
    "ner_message = [\n",
    "    {'role':'system','content': ner_prompt},\n",
    "    {'role':'user','content':f'Input text：{query}'}\n",
    "]\n",
    "concept = chatbot(MESSAGE=ner_message)\n",
    "print(f\"Query NER Result: \\n {concept}\")\n",
    "\n",
    "print(\"-----------------------\")\n",
    "intent_prompt = intent_detector(template)\n",
    "print(f\"Prompt:{intent_prompt}\")\n",
    "print(\"-----------------------\")\n",
    "print(\" \")\n",
    "intent_message = [\n",
    "    {'role':'system','content': intent_prompt},\n",
    "    {'role':'user','content':f'Input text：{query}'}\n",
    "]\n",
    "intent= chatbot(MESSAGE=intent_message)\n",
    "print(f\"User Intent Detection Result: \\n {intent}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the code above, we obtained `the semantic entity set C` and `the query intent set I`. In practical applications, these entity sets and intent sets may be customized according to specific business scenarios. You might be concerned that the recognition rate of large language models is not high enough. However, after our testing, by limiting the candidate range and strictly specifying the output prompt words, large language models can effectively recognize entities and intents. In the tests, the recognition accuracy of large language models was almost 100%. Therefore, we believe that in short-text tasks, large language models have achieved good performance in recognizing entities and intents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C =  {\n",
    "  \"Symptoms\": \"饱食后呕吐半年余，加重1日，餐后呕吐不消化食物，口气臭秽，脘腹胀满，吐后觉舒，大便秘结，泻下酸臭，不完全性肠梗阻，舌质红，苔厚腻，脉滑数有力，指纹紫滞。\",\n",
    "  \"Diseases\": \"呕吐\"  # Based on the symptom description, vomiting is the most matching candidate disease.\n",
    "}\n",
    "\n",
    "I = [\"辩证\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Embedding-based Retrieval of Sub-graphs. \n",
    "\n",
    "Our method extracts pertinent sub-graphs from the knowledge graph, aligned with clinical provided specifics such as \"symptoms\" and \"disease\", as well as clinical intentions like \"syndrome differentiation\". This process consists of two primary steps: EBR-based concepts identification and LLM-driven subgraph extraction.\n",
    "\n",
    "In the **EBR-based concept identification step**, the top $K_{concept}$ most relevant medical concept are pinpointed by harnessing the named entity set C derived from clinical queries. For each entity pair (k,v) ∈ C, cosine similarity is computed between the entity value v and all graph nodes n corresponding to section k via pretrained text embeddings. \n",
    "\n",
    "Aggregating these node-level scores to concept-level by summing contributions from nodes belonging to the same concept, we rank and select the top $K_{concept}$ concepts. This method presupposes that the occurrence of multiple query entities is indicative of pertinent links, thus improving retrieval precision.\n",
    "\n",
    "$$ S_{N_i} = \\sum_{(k,v)\\in C}\\left[\n",
    "    \\sum_{n\\in N_i}\\mathbb{I}\\{n.label=k\\} \\cdot \\cos(\\mathrm{embed}(v),\\mathrm{embed}(n.\\mathrm{text}))\\right] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "饮食积滞证: 0.8537\n",
      "食滞胃热证: 0.8502\n",
      "乳食积滞证: 0.8404\n"
     ]
    }
   ],
   "source": [
    "def retrieve_syndromes(session, C, k=3) -> list[dict]:\n",
    "    query_vector = get_embedding(C[\"Symptoms\"]) # embed(v)\n",
    "    result = session.run(\n",
    "        \"\"\"\n",
    "        MATCH (d:Disease {name: $disease})-[:`HAS_SYNDROME`]->(s:Syndrome)\n",
    "        WITH s, vector.similarity.cosine(s.embedding, $query_vector) AS score\n",
    "        ORDER BY score DESC\n",
    "        LIMIT $top_k\n",
    "        RETURN s.name AS syndrome, score\n",
    "        \"\"\",\n",
    "        disease = C[\"Disease\"],\n",
    "        query_vector = query_vector,\n",
    "        top_k = k\n",
    "    ) \n",
    "    \n",
    "    # \"WITH s, vector.similarity.cosine(s.embedding, $query_vector) AS score\" means:\n",
    "    # \n",
    "    # cos(embed(v),embed(n.text))\n",
    "    # \n",
    "    # Here, n.text refers to the code mentioned above. See the code snippet:\n",
    "    \"\"\"\n",
    "    # Generate embeddings for graph node values using pre-trained text-embedding models such as BERT,\n",
    "    # specifically targeting nodes for text-rich sections\n",
    "    for syndrome in syndromes:\n",
    "        session.execute_write(\n",
    "            node2vec, \n",
    "            syndrome[\"attributes\"][\"name\"], \n",
    "            syndrome[\"attributes\"][\"label\"], \n",
    "            syndrome[\"attributes\"][\"symptoms\"] # text-rich section, the clinical performance of syndrome\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    records = result.data()\n",
    "    return [{\"syndrome\": record[\"syndrome\"], \"score\": record[\"score\"]} for record in records] if records else []\n",
    "\n",
    "with driver.session() as session:\n",
    "    ranked = retrieve_syndromes(\n",
    "        session,\n",
    "        C,\n",
    "        k=3\n",
    "    )\n",
    "    for item in ranked:\n",
    "        print(f\"{item['syndrome']}: {item['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **LLM-driven subgraph extraction step**, the system first rephrases the original user query q to include the retrieved concept entity ID; the modified query q′ is then translated into a graph database language, such as Cypher for Neo4j for question answering. For instance, from the initial query 𝑞 =\"What is the therapeutic methods of Wind-heat exterior syndrome?\", the query is reformulated to \"What is the therapeutic methods of 'SYN0220'?\" and there after transposed into the Cypher query MATCH (s:Syndrome {ID:'SYN0220'})-[:HAS_THERAPY]-> (t:THERAPY) RETURN t.description. \n",
    "\n",
    "> It is worth noting that the LLM-driven query construction is sufficiently flexible. The underlying principle is essentially to guide the language through customized templates and prompts for semantic classification. The code for this part is similar to the LLM parsing of the knowledge graph construction and the user query parsing steps mentioned above, so we will not elaborate further.\n",
    "\n",
    "We can further retrieve the subgraphs (more specific therapy, formula and herbs) based on the top k retrieved syndromes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'concept': '饮食积滞证','text': ['症状：呕吐物酸腐，脘腹胀满拒按，嗳气厌食，得食更甚，吐后反快，大便或溏或结，气味臭秽，苔厚腻，脉滑实。治法：消食化滞，和胃降逆。方药：保和丸']}, {'concept': '保和丸','text': ['方中神曲、山楂、莱菔子消食化滞，陈皮、半夏、茯苓和胃降逆，连翘清散积热。尚可加谷芽、麦芽、鸡内金等消食健胃；若积滞化热，腹胀便秘，可用小承气汤以通腑泄热，使浊气下行，呕吐自止；若食已即吐，口臭干渴，胃中积热上冲，可用竹茹汤清胃降逆；若误食不洁、酸腐食物，而见腹中疼痛，胀满欲吐而不得者，可因势利导，用压舌板探吐祛邪。']}]\n"
     ]
    }
   ],
   "source": [
    "def retrieve_subgraph_based_on_syndromes(session, syndrome_names, hop=1):\n",
    "    query = f\"\"\"\n",
    "        MATCH (s:Syndrome {{name: $syndrome_names}})-[*0..{hop}]-(n)\n",
    "        RETURN n.name AS concept, collect(DISTINCT n.description) AS text\n",
    "    \"\"\"\n",
    "    result = session.run(query, syndrome_names=syndrome_names)\n",
    "    data = result.data()\n",
    "    return data if data else []\n",
    "\n",
    "with driver.session() as session:\n",
    "    retrieved_information = retrieve_subgraph_based_on_syndromes(session, \"饮食积滞证\", hop=1) # here \"饮食积滞证\" is the top 1 potential syndrome\n",
    "    print(retrieved_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Answer Generation. \n",
    "\n",
    "Answers are synthesized by correlating retrieved data from Section 3.2.2 with the initial query. The LLM serves as a decoder to formulate responses to user inquiries given the retrieved information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reference information is:参考信息：\n",
      "饮食积滞证:['症状：呕吐物酸腐，脘腹胀满拒按，嗳气厌食，得食更甚，吐后反快，大便或溏或结，气味臭秽，苔厚腻，脉滑实。治法：消食化滞，和胃降逆。方药：保和丸']\n",
      "保和丸:['方中神曲、山楂、莱菔子消食化滞，陈皮、半夏、茯苓和胃降逆，连翘清散积热。尚可加谷芽、麦芽、鸡内金等消食健胃；若积滞化热，腹胀便秘，可用小承气汤以通腑泄热，使浊气下行，呕吐自止；若食已即吐，口臭干渴，胃中积热上冲，可用竹茹汤清胃降逆；若误食不洁、酸腐食物，而见腹中疼痛，胀满欲吐而不得者，可因势利导，用压舌板探吐祛邪。']\n",
      "\n",
      "------------------------------------------------\n",
      "The prediction of case 1 is: \n",
      " 根据患者的临床信息，结合参考信息，可以推断患者可能患有饮食积滞证。以下是详细的推理过程：\n",
      "\n",
      "1. 患者症状：饱食后呕吐半年余，加重1日，呕吐物酸腐，口气臭秽，脘腹胀满，吐后觉舒，大便秘结，泻下酸臭。\n",
      "2. 舌象：舌质红，苔厚腻，提示体内有湿热积滞。\n",
      "3. 脉象：脉滑数有力，指纹紫滞，表明体内有积热，气血运行不畅。\n",
      "\n",
      "综合以上症状和体征，可以判断患者属于饮食积滞证，治疗原则为消食化滞，和胃降逆。\n",
      "\n",
      "处方建议如下：\n",
      "\n",
      "方药：保和丸加减\n",
      "\n",
      "组成：\n",
      "- 神曲 10g\n",
      "- 山楂 10g\n",
      "- 莱菔子 10g\n",
      "- 陈皮 6g\n",
      "- 半夏 6g\n",
      "- 茯苓 10g\n",
      "- 连翘 10g\n",
      "- 谷芽 10g\n",
      "- 麦芽 10g\n",
      "- 鸡内金 10g\n",
      "\n",
      "加减：\n",
      "- 若腹胀便秘明显，可加小承气汤（大黄、厚朴、枳实）以通腑泄热。\n",
      "- 若胃中积热上冲，口臭干渴，可加竹茹汤（竹茹、生姜、大枣）清胃降逆。\n",
      "- 若误食不洁、酸腐食物，可考虑用压舌板探吐祛邪。\n",
      "\n",
      "用药时需注意：\n",
      "- 本方适用于饮食积滞所致的呕吐，若症状未改善或加重，应及时就医。\n",
      "- 儿童用药需根据体质和病情调整剂量。\n",
      "- 服药期间，患者应避免食用油腻、辛辣、生冷等不易消化的食物。\n"
     ]
    }
   ],
   "source": [
    "reference_information = f\"参考信息：\\n\"\n",
    "for info in retrieved_information:\n",
    "    reference_information += f\"{info['concept']}:{info['text']}\\n\"\n",
    "print(f\"The reference information is:{reference_information}\")\n",
    "print(\"------------------------------------------------\")\n",
    "message = [\n",
    "    {'role':'system','content':'请你扮演一位临床中医师，你的任务是根据给出的临床信息，结合参考信息对当前患者的症状做进一步的推理，最终给出相应处方的中草药组成。'},\n",
    "    # System Prompts: \"Please acting as a clinical traditional Chinese medicine practitioner. \n",
    "    # Your task is to further deduce the patient's symptoms based on the provided clinical information and \n",
    "    # ultimately prescribe the herbal composition of the traditional Chinese medicine.\"\n",
    "    {'role':'user','content':f'临床信息如下：{test[\"question\"]}\\n{reference_information}'}\n",
    "]\n",
    "\n",
    "pred = chatbot(MESSAGE=message)\n",
    "print(f\"The prediction of case {test['id']} is: \\n {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\n",
    "    \"id\": 1, \n",
    "    \"question\": \"患者男，3岁7月。饱食后呕吐半年余，加重1日。患儿半年前无明显诱因出现餐后呕吐不消化食物，口气臭秽，脘腹胀满，吐后觉舒，大便秘结，泻下酸臭，未予以重视，1日前呕吐量较以往增多，行腹部DR提示不完全性肠梗阻。舌质红，苔厚腻，脉滑数有力，指纹紫滞。\",\n",
    "    \"answer\": {\n",
    "        \"symptoms\": [\"呕吐\", \"腹胀\", \"便秘\", \"指纹紫滞\", \"红舌\", \"厚舌苔\", \"腻舌苔\", \"脉有力\", \"数脉\", \"滑脉\"],\n",
    "        \"disease\": \"呕吐\",\n",
    "        \"syndrome\": \"饮食停滞证\",\n",
    "        \"therapy\": [\"消食化滞\",\"和胃降逆\"],\n",
    "        \"formula\": \"保和丸\",\n",
    "        \"herbs\": [\"炒建曲\", \"焦山楂\", \"姜半夏\", \"炒莱菔子\", \"陈皮\", \"连翘\", \"生姜\", \"炒鸡内金\", \"麸炒枳壳\"]\n",
    "    },\n",
    "    \"prediction\": {\n",
    "        \"disease\": \"呕吐\",\n",
    "        \"syndrome\": \"脾胃湿热证\",\n",
    "        \"therapy\": [\"消食导滞\"],\n",
    "        \"formula\": \"枳实导滞丸\",\n",
    "        \"herbs\": [\"黄连\",\"黄芩\",\"厚朴\",\"陈皮\",\"神曲\",\"茯苓\",\"大黄\",\"枳实\",\"甘草\"]\n",
    "    },\n",
    "    \"prediction_rag\": {\n",
    "        \"disease\": \"呕吐\",\n",
    "        \"syndrome\": \"脾胃湿热证\",\n",
    "        \"therapy\": [\"化痰止呕\",\"行气化湿\"],\n",
    "        \"formula\": \"半夏泻心汤\",\n",
    "        \"herbs\": [\"黄连\",\"黄芩\",\"姜半夏\",\"党参\",\"干姜\",\"大枣\",\"炙甘草\",\"茯苓\",\"竹茹\",\"枳实\"]\n",
    "    },\n",
    "    \"prediction_soap\": {\n",
    "        \"disease\": \"呕吐\",\n",
    "        \"syndrome\": \"饮食积滞证\",\n",
    "        \"therapy\": [\"消食化滞\",\"和胃降逆\"],\n",
    "        \"formula\": \"保和丸\",\n",
    "        \"herbs\": [\"神曲\",\"山楂\",\"莱菔子\",\"陈皮\",\"半夏\",\"茯苓\",\"连翘\",\"谷芽\",\"麦芽\",\"鸡内金\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Analysis\n",
    "\n",
    "> Thanks to the hard-coded relation retrieval methods, the model accurately identified the \"Dietary Stagnation Syndrome,\" which is consistent with the standard answer. The proposed treatment principle of \"Digestive Stagnation Elimination and Stomach Harmonization\" perfectly matches clinical needs, aligning with the pathogenesis of food stagnation transforming into heat and obstructed qi movement in children. The selection of \"保和丸\" as the main formula demonstrates a thorough grasp of traditional formula knowledge. The digestive effect of Baohe Pill is milder compared to \"枳实导滞丸\", making it more suitable for children's delicate spleen and stomach, avoiding the risk of excessive purgation that may be caused by drastic purgatives like rhubarb. Although the standard answer includes \"Fresh Ginger\" (for harmonizing the stomach and relieving vomiting) and \"Wheat-Bran Fried Aurantium Shell\" (for promoting qi movement and reducing bloating), the combination of \"Pinellia, Radish Seed, and Tangerine Peel\" still achieves the effect of reducing vomiting and harmonizing the stomach, with an overall focus on safety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment\n",
    "\n",
    "### 4.1 Objective Metrics\n",
    "\n",
    "Our evaluation employed a meticulously curated \"gold\" dataset, comprising typical symptom queries, supporting descriptions, and their authoritative prescriptions. The control group utilized traditional text-based EBR, while the experimental group adopted the method outlined in this study. For both groups, we employed the same LLM, specifically glm-4-flash, and the same embedding model, bge-large-zh-v1.5. We measured retrieval efficacy using Mean Reciprocal Rank (MRR) and Recall@K. MRR gauges the average of the average correct responses, while Recall@K determines the likelihood of relevant items appearing within the top K selections. \n",
    "\n",
    "**For classification tasks and herb recommendation evaluation, we further adopted precision, recall and F1-score metrics:**\n",
    "\n",
    "$$ \n",
    "Precision = \\frac{|\\mathcal{P} \\cap \\mathcal{G}|}{|\\mathcal{P}|},\\quad \n",
    "Recall = \\frac{|\\mathcal{P} \\cap \\mathcal{G}|}{|\\mathcal{G}|},\\quad \n",
    "F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall} \n",
    "$$\n",
    "\n",
    "**where $\\mathcal{P}$ denotes predicted herbs/syndromes and $\\mathcal{G}$ denotes gold-standard items.**\n",
    "\n",
    "$$ \n",
    "MRR = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{rank_i} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\n",
    "    \"id\": 1, \n",
    "    \"answer\": {\n",
    "        \"syndrome\": \"饮食积滞证\",\n",
    "        \"formula\": \"保和丸\",\n",
    "        \"therapy\": [\"消食化滞\",\"和胃降逆\"],\n",
    "        \"herbs\": [\"炒建曲\",\"焦山楂\",\"姜半夏\",\"炒莱菔子\",\"陈皮\",\"连翘\",\"生姜\",\"炒鸡内金\",\"麸炒枳壳\"]\n",
    "    },\n",
    "    \"prediction_rag\": {\n",
    "        \"topk\": [\"脾胃湿热证\",\"食滞胃热证\",\"饮食积滞证\"], # # top 3 syndromes predicted by convential RAG\n",
    "        \"syndrome\": \"脾胃湿热证\",\n",
    "        \"formula\": \"半夏泻心汤\",\n",
    "        \"therapy\": [\"化痰止呕\",\"行气化湿\"],\n",
    "        \"herbs\": [\"黄连\",\"黄芩\",\"姜半夏\",\"党参\",\"干姜\",\"大枣\",\"炙甘草\",\"茯苓\",\"竹茹\",\"枳实\"]\n",
    "    },\n",
    "    \"prediction_soap\": {\n",
    "        \"topk\": [\"饮食积滞证\",\"食滞胃热证\",\"乳食积滞证\"], # top 3 syndromes predicted by SOAP-G\n",
    "        \"syndrome\": \"饮食积滞证\",\n",
    "        \"formula\": \"保和丸\",\n",
    "        \"therapy\": [\"消食化滞\",\"和胃降逆\"],\n",
    "        \"herbs\": [\"神曲\",\"山楂\",\"莱菔子\",\"陈皮\",\"半夏\",\"茯苓\",\"连翘\",\"谷芽\",\"麦芽\",\"鸡内金\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syndrome retrieval metrics:\n",
      "RAG: MRR=0.333, Recall@3=1\n",
      "SOAP: MRR=1.000, Recall@3=1\n",
      "\n",
      "Classification accuracy:\n",
      "RAG: Syndrome=0, Formula=0, Therapy=0\n",
      "SOAP: Syndrome=1, Formula=1, Therapy=1\n",
      "\n",
      "Herb recommendation metrics:\n",
      "RAG: Precision=0.100, Recall=0.111, F1=0.105\n",
      "SOAP: Precision=0.200, Recall=0.222, F1=0.211\n"
     ]
    }
   ],
   "source": [
    "# Normalization function (adjust according to actual needs)\n",
    "def normalize_herb(herb):\n",
    "    prefixes = ['roasted', 'ginger', 'charred', 'wheat-fried', 'fried', 'prepared']\n",
    "    for prefix in prefixes:\n",
    "        if herb.startswith(prefix):\n",
    "            return herb[len(prefix):]\n",
    "    return herb\n",
    "\n",
    "# MRR calculation function\n",
    "def calculate_mrr(gold, predictions):\n",
    "    ranks = []\n",
    "    for pred in predictions:\n",
    "        if 'topk' not in pred: continue\n",
    "        rank = pred['topk'].index(gold) + 1 if gold in pred['topk'] else float('inf')\n",
    "        ranks.append(1/rank if rank != float('inf') else 0)\n",
    "    return sum(ranks)/len(ranks) if ranks else 0\n",
    "\n",
    "# Recall@K calculation function\n",
    "def calculate_recall(gold, predictions, k=3):\n",
    "    recalls = []\n",
    "    for pred in predictions:\n",
    "        if 'topk' not in pred: continue\n",
    "        recalls.append(1 if gold in pred['topk'][:k] else 0)\n",
    "    return sum(recalls)/len(recalls) if recalls else 0\n",
    "\n",
    "# Herb evaluation function\n",
    "def herb_metrics(gold_herbs, pred_herbs):\n",
    "    gold_set = set(normalize_herb(h) for h in gold_herbs)\n",
    "    pred_set = set(normalize_herb(h) for h in pred_herbs)\n",
    "    tp = len(gold_set & pred_set)\n",
    "    precision = tp / len(pred_set) if pred_set else 0\n",
    "    recall = tp / len(gold_set) if gold_set else 0\n",
    "    f1 = 2*(precision*recall)/(precision+recall) if (precision+recall) else 0\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Main calculation process\n",
    "if __name__ == \"__main__\":\n",
    "    gold = test['answer']\n",
    "    models = {\n",
    "        'RAG': test['prediction_rag'],\n",
    "        'SOAP': test['prediction_soap']\n",
    "    }\n",
    "    \n",
    "    # Syndrome retrieval metrics\n",
    "    print(\"Syndrome retrieval metrics:\")\n",
    "    for name, pred in models.items():\n",
    "        if 'topk' not in pred: continue\n",
    "        rank = pred['topk'].index(gold['syndrome'])+1 if gold['syndrome'] in pred['topk'] else None\n",
    "        mrr = 1/rank if rank else 0\n",
    "        recall = 1 if gold['syndrome'] in pred['topk'][:3] else 0\n",
    "        print(f\"{name}: MRR={mrr:.3f}, Recall@3={recall}\")\n",
    "\n",
    "    # Classification accuracy\n",
    "    print(\"\\nClassification accuracy:\")\n",
    "    for name, pred in models.items():\n",
    "        syndrome_acc = int(pred['syndrome'] == gold['syndrome'])\n",
    "        formula_acc = int(pred['formula'] == gold['formula'])\n",
    "        therapy_acc = int(pred['therapy'] == gold['therapy'])\n",
    "        print(f\"{name}: Syndrome={syndrome_acc}, Formula={formula_acc}, Therapy={therapy_acc}\")\n",
    "\n",
    "    # Herb recommendation metrics\n",
    "    print(\"\\nHerb recommendation metrics:\")\n",
    "    for name, pred in models.items():\n",
    "        p, r, f = herb_metrics(gold['herbs'], pred['herbs'])\n",
    "        print(f\"{name}: Precision={p:.3f}, Recall={r:.3f}, F1={f:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Syndrome Retrieval:\n",
    "> - The MRR of KG-RAG is 1.0 (the correct syndrome is ranked first).\n",
    "> - The MRR of RAG is 0.333 (the correct syndrome is ranked third).\n",
    "> \n",
    "> Classification Accuracy:\n",
    "> - KG-RAG is accurate in all three aspects: syndrome, formula, and therapy.\n",
    "> - RAG is inaccurate in all three aspects.\n",
    "> \n",
    "> Herb Recommendation:\n",
    "> - The F1 score of KG-RAG is 0.526 (5 common herbs with the standard answer after normalization).\n",
    "> - The F1 score of RAG is 0.105 (only 1 common herb).\n",
    "> The implementation considers the following key points:\n",
    "> - Standardization of traditional Chinese medicine (TCM) names (removing prefixes related to processing).\n",
    "> Boundary checks on the topk list.\n",
    "> Strict matching of classification metrics.\n",
    "> Multi-dimensional evaluation (retrieval, classification, and recommendation).\n",
    "> \n",
    "> In practical applications, the following are needed: Expansion of the test case set. Optimization of TCM standardization rules. Addition of a human evaluation module. Support for batch calculation and statistical summarization. The normalization rules in the normalize_herb() function can be adjusted to accommodate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Professional Physician Evaluation\n",
    "\n",
    "Given that automatically generating traditional Chinese medicine (TCM) prescriptions is an extremely complex task, I invited professional TCM practitioners to evaluate the generated TCM prescriptions. The evaluators were required to score the generated prescriptions in the following two aspects: 1) Herb Effectiveness (HE) and 2) Herb Compatibility (HC). The value range for both scores is [0,10]. Higher scores indicate better effectiveness and compatibility of the prescriptions, and vice versa. The doctors evaluated based on theories, principles, prescriptions, and their own TCM experience. In addition to the generated prescriptions, the invited doctors were also required to evaluate the labeled prescriptions as a benchmark for the generated ones. Unlike automatic evaluation methods, human evaluators focus on the potential effectiveness of candidate answers, rather than just literal similarity, which is more rational and relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this script, we present some code snippets and comments on how the prescription generation system based on Large Language Models (LLM) works. This system seamlessly integrates Retrieval-Augmented Generation (RAG) with semantic networks constructed in a Knowledge Graph (KG).\n",
    "To put it simply, by `introducing semantic labels`, we have addressed the issue of text inconsistency in traditional retrieval-augmented methods. This has enabled more flexible and accurate prescription generation recommendations. However, it is evident that we still need to `manually write templates and construct the knowledge base`. In practical applications, we also encounter more complex and difficult-to-recognize text storage formats, such as PDF. Currently, I am using `from llama_index.readers.file import PDFReader`, but the text conversion results are not satisfactory. I am still working on resolving this issue (a potential solution is `olmocr`, see the following link: GitHub - [allenai/olmocr: Toolkit for linearizing PDFs for LLM datasets/training](https://github.com/allenai/olmocr), but currently I do not have a high-quality GPU to run it). Nonetheless, I will continue to seek a cost-effective and efficient way to address this challenge.\n",
    "\n",
    "If you encounter any issues or have questions while reading this note, please feel free to contact me at mc36401@um.edu.mo. I will open-source all the code and the prescription dataset in the near future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\"\"\"\n",
    "Some tips for you:\n",
    "This is just a simple PDF reader that uses the LlamaIndex library to extract text from PDFs.\n",
    "But if you have enough GPU resources, I strongly recommend using the OLM OCR model to extract text from PDFs.\n",
    "It has much better performance than the other PDF reader libs. The only problem is that it is required to use high-end GPU.\n",
    "\n",
    "- Recent NVIDIA GPU (tested on RTX 4090, L40S, A100, H100, A6000...) with at least 20 GB of GPU RAM\n",
    "- Follow: https://github.com/allenai/olmocr\n",
    "\"\"\"\n",
    "\n",
    "def pdfreader(file_path:str)->str:\n",
    "    assert os.path.exists(file_path), \"File does not exist\"\n",
    "    assert file_path.endswith(\".pdf\"), \"File format not supported\"\n",
    "\n",
    "    from llama_index.readers.file import PDFReader\n",
    "    doc = PDFReader().load_data(file=Path(file_path))\n",
    "\n",
    "    text = \"\\n\\n\".join([d.get_content() for d in doc])\n",
    "    return text\n",
    "\n",
    "def plainreader(file_path:str)->str:\n",
    "    assert os.path.exists(file_path), \"File does not exist\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
